#!/usr/bin/env python3
import requests,argparse,random,string
from time import sleep
from tqdm import tqdm

found = []
JITTER = 100

def check_url(ROOT_URL):
	if ROOT_URL.endswith("/"):
		count_words(ROOT_URL,WORDLIST_PATH)
	else:
		ROOT_URL = ROOT_URL + "/"
		count_words(ROOT_URL,WORDLIST_PATH)


def count_words(ROOT_URL,WORDLIST_PATH):
	wordlist_length = 0
	with open(WORDLIST_PATH,"r") as wordlist:
		for line in wordlist:
			wordlist_length = wordlist_length + 1
		wordlist.close()
	print("[+] Wordlist contains {0} words.".format(wordlist_length))
	generate_baseline(ROOT_URL,32,wordlist_length)

def generate_baseline(ROOT_URL,string_length,wordlist_length):
	all_chars = string.ascii_letters + string.digits
	random_dir = ''.join(random.choice(all_chars) for x in range(string_length))
	baseline_request = ROOT_URL + random_dir
	r0 = requests.get(baseline_request)
	baseline_response = len(r0.text)
	print("[+] Baseline Request Length: {0}".format(baseline_response))
	threshold_low = baseline_response - JITTER
	threshold_high = baseline_response + JITTER	
	print("[+] Exclusion Range: {0} - {1}".format(threshold_low,threshold_high))

	brute_force(ROOT_URL,wordlist_length,threshold_low,threshold_high)


def brute_force(ROOT_URL,wordlist_length,threshold_low,threshold_high):
	progress_counter = 0
	with open(WORDLIST_PATH,"r") as wordlist:
		for word in tqdm(wordlist, total=wordlist_length, desc="[+] Progress"):
			url = ROOT_URL + word.rstrip()
			try:
				r = requests.get(url, timeout=TIMEOUT)
				response = len(r.text)
				if(response <= threshold_low or response >= threshold_high):
					found.append(word.rstrip() + " [Length: " + str(response) + "]" )
					sleep(0.5)
			except Exception as e:
				print("[!] Error encountered: {0}".format(e))
	wordlist.close()
	if found:
		num_found = len(found)
		print("[+] Found {0} directories!".format(num_found))
		for word in found:
			print("  [+] {0}".format((ROOT_URL + word)))



desc = "200Buster: Directory Busting for web applications that always return '200 OK.'"
parser = argparse.ArgumentParser(description=desc)
parser.add_argument('-w', metavar='Wordlist', required=True, help='Ex: /usr/share/wordlists/dirb/common.txt')
parser.add_argument('-u', metavar='URL', required=True, help='Ex: http://www.example.com/')
parser.add_argument('-j', metavar='Jitter', help='Ex: 100 (exclude 100-byte difference) ')
parser.add_argument('-t', metavar='Timeout', help='Ex: 1 (1 second)')
args = parser.parse_args()

if args.u:
	ROOT_URL = args.u
	if args.w:
		WORDLIST_PATH = args.w
	if args.t:
		TIMEOUT = float(args.t)
	if not args.t:
		TIMEOUT = 0.5
	if args.j:
		JITTER = int(args.j)
	if not args.j:
		JITTER = 100
	check_url(ROOT_URL)

else:
	parser.print_help()
